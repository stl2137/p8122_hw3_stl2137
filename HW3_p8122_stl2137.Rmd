---
title: "P8122 HW3"
author: "Sabrina Lin stl2137"
date: "11/21/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tableone)
library(mlogit)
library(personalized)
```

# Part 1

```{r}
### read in data
salary_dat <- read_csv("/Users/SabrinaLin/Documents/Fall_2020_Causal_Inference/Homework/HW3/p8122_hw3_stl2137/hW3\ data.csv") %>% 
  mutate(
    treat = as.factor(treat),
    black = as.factor(black),
    hispan = as.factor(hispan),
    married = as.factor(married),
    nodegree = as.factor(nodegree)
  )

salary_dat <- as.data.frame(salary_dat)
```


* data consists of 10 variables measured for each individual:

  * an indicator of treatment assignment (job training), `treat` 
  
  * age in years, `age`
  
  * education in years, `educ`
  
  * an indicator for African-American, `black` 
  
  * an indicator for Hispanic, `hispan`
  
  * an indicator for married, `married`
  
  * an indicator for high school degree, `nodegree`
  
  * income in 1974, `re74` 
  
  * income in 1975 `re75` 
  
  * income in 1978, `re78`

* The variable `treat` is the treatment and the variables `re78` is the outcome.

## Subpart 1
Write the DAG representing this observational study including all variables provided. Describe all the variables in the graph.


## Subpart 2
Evaluate covariate balance in this observational study. Show a table or a plot. Interpret the results.

```{r}
## Construct a table
vars <- c("age", "educ", "black", "hispan", "married", "nodegree", "re74", "re75", "re78")

tab_presub <- CreateTableOne(vars = vars, strata = "treat", data = salary_dat, test = FALSE)

print(tab_presub, smd = TRUE)
```

* Given that we would like the SMD to be less than 0.2 and having seen 0.25 as a common guideline for SMD in the literature, there are several variables that surpass this rule of thumb. The SMD (standardized mean difference) for the variable `black` is very large at 1.671, indicating that the covariate balance for this variable is not good. The variables `married` and `re74` also have relatively large SMDs (0.721 and 0.596 respectively), also indicating that the covariate balance for these variables is not great. 

## Subpart 3
The propensity score is defined as the probability of receiving the treatment given the observed covariates. These scores are used to construct strata within which we assume that the exposure assignment is random. Construct propensity scores by fitting a logistic regression to the data.

```{r}
salary_mlogit_dat <- mlogit.data(salary_dat, choice = "treat", shape = "wide")
fit_sal <- mlogit(treat ~ 0 | age + educ + black + hispan + married + nodegree + re74 + re75, data = salary_mlogit_dat)
summary(fit_sal)

ps_model <- glm(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = salary_dat, family = binomial)
summary(ps_model)

salary_dat$ps <- predict(ps_model, type = "response")

```

# Subpart 4
Given the propensity scores estimated, evaluate overlap. Trim data if necessary and evaluate the impact of trimming in your analytic sample on efficiency and generalizability.

```{r}
### visualization of overlap 

prop_func <- function(x, trt)
{
    # fit propensity score model
  propens.model <- glm(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = salary_dat, family = binomial)
  pi.x <- predict(propens.model, type = "response")
  pi.x
}

check.overlap(x = salary_dat,
              trt = salary_dat$treat,
              propensity.func = prop_func)

### now add density plot with histogram

check.overlap(x = salary_dat,
              trt = salary_dat$treat,
              type = "both",
              propensity.func = prop_func)
```

```{r}
ps <- salary_dat$ps

#eliminate non comparable cases and generate the analytic data

### eliminate controls where the P(A=1|C) is less than the min(P(A=1|C)) found in the treated group
min(ps[salary_dat$treat==1])
ps[which(salary_dat$treat==0)] <=min(ps[salary_dat$treat==1])
length(ps[which(salary_dat$treat==0)]<= min(ps[salary_dat$treat==1]))

#eliminate treated where the P(A=1|C) is greater that the max(P(A=1|C)) found in the control group
max(ps[salary_dat$treat==0])
ps[which(salary_dat$treat==1)]>= max(ps[salary_dat$treat==0])

length(ps[which(salary_dat$treat==0)]<= min(ps[salary_dat$treat==0]))

data = salary_dat[ps>=min(ps[salary_dat$treat==1]) & ps <= max(ps[salary_dat$treat==0]),]
dim(salary_dat)
dim(data)
```

* After trimming the data, we lose `r dim(salary_dat)[1] - dim(data)[1]` observations. Although trimming these `r dim(salary_dat)[1] - dim(data)[1]` observations improves the internal validity since we are able to ensure comparability for the remaining units, it hurts generalizability because we are excluding certain people in the population to get to a better causal effect. 

## Subpart 5
Evaluate covariate balance in the trimmed sample.

```{r}
tab_postsub <- CreateTableOne(vars = vars, strata = "treat", data = data, test = FALSE)

print(tab_presub, smd = TRUE)

print(tab_postsub, smd = TRUE)
```

* Comparing the pre- and post- trimmed samples, the post-trimmed samples had lower SMDs compared to the pre-trimmed samples. The SMDs that were high in the pre-trimmed sample (`black`, `married`, `re74`) are lower in the post-trimmed sample (`black` decreased from 1.671 to 1.515, `married` decreased from 0.721 to 0.534, `re74` decreased from 0.596 to 0.363.) Although they have decreased, all 3 variables RMDs are still higher than the threshold of 0.2 (as given in class) or 0.25 (found independently in the literature). 

```{r}
### visualization of overlap post trimming

prop_func_post_trim <- function(x, trt)
{
    # fit propensity score model
  propens.model <- glm(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = data, family = binomial)
  pi.x <- predict(propens.model, type = "response")
  pi.x
}

check.overlap(x = data,
              trt = data$treat,
              propensity.func = prop_func_post_trim)

### now add density plot with histogram

check.overlap(x = data,
              trt = data$treat,
              type = "both",
              propensity.func = prop_func_post_trim)
```

* Looking at the post-trimming density plot, we can visually see that trimming has made the covariate balance better than pre-trimming; however, it is still not ideal. 

## Subpart 6
Using the propensity scores estimated use subclassification to balance covariates between treated and controls. Explain your process, report the breaks you decide on for your subclasses, show a plot of the propensity scores with these breaks. Inspect covariate balance for each subclass.

```{r}
### creating subclasses attempt 1
subclass.breaks = quantile(ps, c(.20, .40, .60, .80)) # bins (initial try - modify as needed)
subclass = data$ps
subclass = as.numeric(data$ps>subclass.breaks[1])
subclass[which(data$ps>subclass.breaks[1]& data$ps<=subclass.breaks[2])]<- 1
subclass[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])]<- 2
subclass[which(data$ps>subclass.breaks[3])]<- 3

table(data$treat, subclass) # doesn't violate overlap, but we can try for better
```

* Although overlap is not technically violated, the balance for the first subgroup is extremely poor. The second subgroup also does not have great balance, so we will continue trying subclassification at different percentile breaks. 

```{r}
#creating subclasses
subclass.breaks = quantile(data$ps, c(.25, .50, .75)) 
subclass = data$ps
subclass = as.numeric(data$ps>subclass.breaks[1])
subclass[which(data$ps>subclass.breaks[1]& data$ps<=subclass.breaks[2])]<- 1
subclass[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])]<- 2
subclass[which(data$ps>subclass.breaks[3])]<- 3

table(data$treat, subclass) # doesn't violate overlap, but try for better
```

* The first and second subgroup balance is still not fantastic, so we will continue trying subclassification at different percentile breaks. 

```{r}
#creating subclasses
subclass.breaks = quantile(data$ps, c(.33, 0.67)) 
subclass = data$ps
subclass = as.numeric(data$ps>subclass.breaks[1])
subclass[which(data$ps>subclass.breaks[1]& data$ps<=subclass.breaks[2])]<- 1
subclass[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])]<- 2
subclass[which(data$ps>subclass.breaks[3])]<- 3

table(data$treat, subclass)
```

* Although the second subgroup has really good balance, the first subgroup has poor balance. We will continue trying aditional subclassification percentiles. 

```{r}
#creating subclasses
subclass.breaks = quantile(data$ps, c(.48, 0.5, 0.75)) 
subclass = data$ps
subclass = as.numeric(data$ps>subclass.breaks[1])
subclass[which(data$ps>subclass.breaks[1]& data$ps<=subclass.breaks[2])]<- 1
subclass[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])]<- 2
subclass[which(data$ps>subclass.breaks[3])]<- 3

table(data$treat, subclass)
```

* After additional searching, having 4 subclasses with percentile breaks at 0.48, 0.5, and 0.75 seems to lead to better balance across the subclasses. Although the first subclass still has sub-optimal covariate balance and the last subclass does not have the best covariate balance, the second and third subclasses have pretty good balance. We will proceed to inspect the covariate balance for each subclass more in depth. 

```{r}
#looking at propensity scores within subclasses
prop.func <- function(x, trt)
{
  
  data$ps[which(data$ps <= subclass.breaks[1])]
}
#data$ps <-ps
check.overlap(x = data[which(data$ps <=subclass.breaks[1]),],
              trt = data$treat[which(data$ps <= subclass.breaks[1])],
              type = "both",
              propensity.func = prop.func)


prop.func <- function(x, trt)
{
 
  data$ps[which(data$ps>subclass.breaks[1]&data$ps<=subclass.breaks[2])]
}
#data$ps <-ps
check.overlap(x = data[which(data$ps>subclass.breaks[1]&data$ps<=subclass.breaks[2]),],
              trt = data$treat[which(data$ps>subclass.breaks[1]&data$ps<=subclass.breaks[2])],
              type = "both",
              propensity.func = prop.func)

prop.func <- function(x, trt)
{
  
  data$ps[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])]
}
#data$ps <-ps
check.overlap(x = data[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3]),],
              trt = data$treat[which(data$ps>subclass.breaks[2]&data$ps<=subclass.breaks[3])],
              type = "both",
              propensity.func = prop.func)



 prop.func <- function(x, trt)
 {
   
   data$ps[which(data$ps>subclass.breaks[3])]
 }
 #data$ps <-ps
 check.overlap(x = data[which(data$ps>subclass.breaks[3]),],
               trt = data$treat[which(data$ps>subclass.breaks[3])],
               type = "both",
               propensity.func = prop.func)
 

```

```{r}
tab_s0 <- CreateTableOne(vars = vars, strata = "treat", data = data[which(subclass==0),], test = FALSE)
tab_s1 <- CreateTableOne(vars = vars, strata = "treat", data = data[which(subclass==1),], test = FALSE)
tab_s2 <- CreateTableOne(vars = vars, strata = "treat", data = data[which(subclass==2),], test = FALSE)
tab_s3 <- CreateTableOne(vars = vars, strata = "treat", data = data[which(subclass==3),], test = FALSE)

## Show table with SMD

print(tab_s0, smd = TRUE)
print(tab_s1, smd = TRUE)
print(tab_s2, smd = TRUE)
print(tab_s3, smd = TRUE)
```

# Part 2

a) Write the non-parametric structural equation model associated with it.

b) Does conditioning on L properly adjust for confounding if we used the definition of confounder based on the backdoor criterion? Justify your answer.


## DAG 1

$Y = f_Y(A, L, \epsilon_Y)$

$A = f_A(L, \epsilon_A)$ 

$L = f_L(\epsilon_L)$

* Conditioning on L would properly adjust for confounding, as it would block the path A-L-Y. 

## DAG 2

$Y = f_Y(U, A, L, \epsilon_Y)$

$A = f_A(L, \epsilon_A)$ 

$L = f_L(U, \epsilon_L)$

$U = f_U(\epsilon_U)$

* Conditioning on L would properly adjust for confounding, as it would block the path A-L-U-Y. 

## DAG 3

$Y = f_Y(U, \epsilon_Y)$

$U = f_U(\epsilon_U)$

$L = f_L(U, A, \epsilon_L)$ 

$A = f_A(\epsilon_A)$

* Conditioning on L would not properly adjust for confounding. In this DAG, A is not associated with Y. 

## DAG 4

$Y = f_Y(A, L, \epsilon_Y)$

$A = f_A(U, \epsilon_A)$

$L = f_L(U, \epsilon_L)$ 

$U = f_U(\epsilon_U)$

* Conditioning on L would properly adjust for confounding, as it would block the path A-U-L-Y. 

## DAG 5

$Y = f_Y(A, U_1, \epsilon_Y)$

$A = f_A(U_2, \epsilon_A)$

$U_2 = f_{U_2}(\epsilon_{U_2})$

$U_1 = f_{U_1}(\epsilon_{U_1})$

$L = f_L(U_1, U_2, \epsilon_L)$ 

* Conditioning on L would not properly adjust for confounding, as L is a collider. Thus, we do not want to condition on L. 